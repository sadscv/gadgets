{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding:utf-8 _*-\n",
    "\"\"\"\n",
    "@author: sadscv\n",
    "@file: mdb2csv.py\n",
    "@time: 2019/01/13 12:47\n",
    "# Dump each table in an .mdb file to CSV files.\n",
    "\"\"\"\n",
    "import os\n",
    "import sqlite3\n",
    "\n",
    "import pandas\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "DATABASE = sys.argv[1]\n",
    "\n",
    "\n",
    "def mdb2csv(tables, database):\n",
    "    \"\"\"\n",
    "\n",
    "    :param tables:\n",
    "    :param database:\n",
    "    :return: list of filepath e.g. ~/AutoExam/data/2018-2019***.csv\n",
    "    \"\"\"\n",
    "    files = []\n",
    "    count = 0\n",
    "    for t in tables:\n",
    "        if t != '':\n",
    "            # converting \" \" in table names to \"_\" for the CSV filenames.\n",
    "            contents = subprocess.Popen([\"mdb-export\", database,\n",
    "                                        str(t, encoding='utf8').replace(\" \", \"_\")],\n",
    "                                        stdout=subprocess.PIPE).communicate()[0]\n",
    "            if len(contents) != 0:\n",
    "                print('start', count)\n",
    "                print(len(contents))\n",
    "                print('\\nend')\n",
    "                count += 1\n",
    "                filename = str(t, encoding='utf8').replace(\" \", \"_\") + str(\".csv\")\n",
    "                file = open('./data/csv/'+filename, 'w+')\n",
    "                # print(\"Dumping \" + filename)\n",
    "                # Dump each table as a CSV file using \"mdb-export\",\n",
    "                file.write(str(contents, encoding='utf8'))\n",
    "                file.close()\n",
    "                # files.append(file.name)\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            raise FileNotFoundError('{} is null'.format(t))\n",
    "    # Todo:this may cause bugs.\n",
    "    # should init or clean the csv file directory before use it\n",
    "    return files\n",
    "\n",
    "\n",
    "def mdb_converter(db, f_type='sqlite'):\n",
    "    schema = subprocess.Popen([\"mdb-schema\", db, \"mysql\"],\n",
    "                              stdout=subprocess.PIPE).communicate()[0]\n",
    "    # Get the list of table names with \"mdb-tables\"\n",
    "    table_names = subprocess.Popen([\"mdb-tables\", \"-1\", db],\n",
    "                                   stdout=subprocess.PIPE).communicate()[0]\n",
    "    tables = table_names.splitlines()\n",
    "    print(\"BEGIN\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    # Dump each table in .mdb file to an CSV file\n",
    "    if f_type == 'csv':\n",
    "        files = mdb2csv(tables, DATABASE)\n",
    "        print('Successful dump csv files:')\n",
    "        print(files)\n",
    "\n",
    "    # dump .mdb file to sqlite file\n",
    "    if f_type == 'sqlite':\n",
    "        files = mdb2csv(tables, DATABASE)\n",
    "        print(files)\n",
    "        conn = sqlite3.connect(os.path.curdir + '/data/data.sqlite')\n",
    "        cur = conn.cursor()\n",
    "        # Todo: init or delete data.sqlite before execute following script\n",
    "        cur.executescript(str(schema, encoding='utf8'))\n",
    "        cur.close()\n",
    "        conn.commit()\n",
    "        # print(str(tables, encoding='utf8'))\n",
    "        print(len(tables))\n",
    "        for t in tables:\n",
    "            pass\n",
    "            # print(str(t, encoding='utf8'))\n",
    "        for file in files:\n",
    "            if file != '':\n",
    "                # subprocess.call([\"mdb-export\", \"-I\", \"mysql\", DATABASE, file])\n",
    "                #note: read_csv:head=None\n",
    "                df = pandas.read_csv(os.path.join(os.path.curdir, 'data/csv/', file),\n",
    "                                     delimiter='\\t', error_bad_lines=False)\n",
    "                df.to_sql(file[:-4], conn, if_exists='append', index=False)\n",
    "        print(\"COMMIT\")\n",
    "        conn.close()\n",
    "        sys.stdout.flush()\n",
    "\n",
    "############\n",
    "# import csv, sqlite3\n",
    "#\n",
    "# cur.execute(\"CREATE TABLE t (col1, col2);\") # use your column names here\n",
    "#\n",
    "# with open('data.csv','rb') as fin: # `with` statement available in 2.5+\n",
    "#     # csv.DictReader uses first line in file for column headings by default\n",
    "#     dr = csv.DictReader(fin) # comma is default delimiter\n",
    "#     to_db = [(i['col1'], i['col2']) for i in dr]\n",
    "#\n",
    "# cur.executemany(\"INSERT INTO t (col1, col2) VALUES (?, ?);\", to_db)\n",
    "# con.commit()\n",
    "# con.close()\n",
    "###########\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mdb_converter(DATABASE, f_type='sqlite')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
